{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRbpJSPDj/2Pu96TrLTc7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtemBaron/baron_vergeles/blob/main/spark_when_expr_lit_split_concat_ws_substring_regexp_replace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "380IFIENYGcN",
        "outputId": "b32e0a12-83a6-4187-f07f-71cac7c99574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=ae11353ee0d28eea72e783e870af979359b7b2e5a2a706495bd532fc9fe45e46\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark\n",
        "#https://sparkbyexamples.com/pyspark/pyspark-convert-array-column-to-string-column/?expand_article=1\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('test').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as f"
      ],
      "metadata": {
        "id": "8zEr7hDbbvHG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"James\",\"M\",60000),(\"Michael\",\"M\",70000),\n",
        "        (\"Robert\",None,400000),(\"Maria\",\"F\",500000),\n",
        "        (\"Jen\",\"\",None)]\n",
        "\n",
        "columns = [\"name\",\"gender\",\"salary\"]\n",
        "df = spark.createDataFrame(data = data, schema = columns)"
      ],
      "metadata": {
        "id": "b5q77V8tb327"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7_K2hDCcvlF",
        "outputId": "2e5f8f2a-5049-43e2-dd72-1883e40fb0c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------+\n",
            "|   name|gender|salary|\n",
            "+-------+------+------+\n",
            "|  James|     M| 60000|\n",
            "|Michael|     M| 70000|\n",
            "| Robert|  null|400000|\n",
            "|  Maria|     F|500000|\n",
            "|    Jen|      |  null|\n",
            "+-------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.withColumn(\"new_gender\", f.when(df.gender == \"M\",\"Male\")\n",
        "                                 .when(df.gender == \"F\",\"Female\")\n",
        "                                 .when(df.gender.isNull() ,\"\")\n",
        "                                 .otherwise(df.gender))\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiEDhbQvcvuq",
        "outputId": "e252e76c-2184-4ba3-c5c4-5ca49208b694"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------+----------+\n",
            "|   name|gender|salary|new_gender|\n",
            "+-------+------+------+----------+\n",
            "|  James|     M| 60000|      Male|\n",
            "|Michael|     M| 70000|      Male|\n",
            "| Robert|  null|400000|          |\n",
            "|  Maria|     F|500000|    Female|\n",
            "|    Jen|      |  null|          |\n",
            "+-------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df.select(\"*\",f.when(df.gender == \"M\",\"Male\")\n",
        "                  .when(df.gender == \"F\",\"Female\")\n",
        "                  .when(df.gender.isNull() ,\"\")\n",
        "                  .otherwise(df.gender).alias(\"new_gender\"))\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBlQ2aXtcv1w",
        "outputId": "0e052cd8-2bb4-476e-812f-7edc163bca84"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------+----------+\n",
            "|   name|gender|salary|new_gender|\n",
            "+-------+------+------+----------+\n",
            "|  James|     M| 60000|      Male|\n",
            "|Michael|     M| 70000|      Male|\n",
            "| Robert|  null|400000|          |\n",
            "|  Maria|     F|500000|    Female|\n",
            "|    Jen|      |  null|          |\n",
            "+-------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df.select(\"*\", f.expr(\"CASE WHEN gender = 'M' THEN 'Male' \" +\n",
        "           \"WHEN gender = 'F' THEN 'Female' WHEN gender IS NULL THEN ''\" +\n",
        "           \"ELSE gender END\").alias(\"new_gender\"))\n",
        "df4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YZw42Fscv7k",
        "outputId": "eb535601-33bc-430e-e645-859456c584b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------+----------+\n",
            "|   name|gender|salary|new_gender|\n",
            "+-------+------+------+----------+\n",
            "|  James|     M| 60000|      Male|\n",
            "|Michael|     M| 70000|      Male|\n",
            "| Robert|  null|400000|          |\n",
            "|  Maria|     F|500000|    Female|\n",
            "|    Jen|      |  null|          |\n",
            "+-------+------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(\"James\",\"Bond\"),(\"Scott\",\"Varsa\")]\n",
        "df=spark.createDataFrame(data).toDF(\"col1\",\"col2\")\n",
        "df.withColumn(\"Name\",f.expr(\" col1 ||','|| col2\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM0hHLF2cwAn",
        "outputId": "a22dd135-6ef6-4fc5-edf2-a3daf57e2e8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-----------+\n",
            "| col1| col2|       Name|\n",
            "+-----+-----+-----------+\n",
            "|James| Bond| James,Bond|\n",
            "|Scott|Varsa|Scott,Varsa|\n",
            "+-----+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"James\",\"M\"),(\"Michael\",\"F\"),(\"Jen\",\"\")]\n",
        "columns = [\"name\",\"gender\"]\n",
        "df = spark.createDataFrame(data = data, schema = columns)\n",
        "df2=df.withColumn(\"gender\", f.expr(\"CASE WHEN gender = 'M' THEN 'Male' \" +\n",
        "           \"WHEN gender = 'F' THEN 'Female' ELSE 'unknown' END\"))\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUXUqAqScwFE",
        "outputId": "a5cc3cbd-d8eb-4d0a-a040-3957d642fc59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+\n",
            "|   name| gender|\n",
            "+-------+-------+\n",
            "|  James|   Male|\n",
            "|Michael| Female|\n",
            "|    Jen|unknown|\n",
            "+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(\"2019-01-23\",1),(\"2019-06-24\",2),(\"2019-09-20\",3)]\n",
        "df=spark.createDataFrame(data).toDF(\"date\",\"increment\")\n",
        "\n",
        "#Add Month value from another column\n",
        "df.select(df.date,df.increment,\n",
        "     f.expr(\"add_months(date,increment)\")\n",
        "    .alias(\"inc_date\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdhKEmx_cwKH",
        "outputId": "620213db-0aaa-4ff4-ed13-176e9e65b0e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+----------+\n",
            "|      date|increment|  inc_date|\n",
            "+----------+---------+----------+\n",
            "|2019-01-23|        1|2019-02-23|\n",
            "|2019-06-24|        2|2019-08-24|\n",
            "|2019-09-20|        3|2019-12-20|\n",
            "+----------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Providing alias using 'as'\n",
        "from pyspark.sql.functions import expr\n",
        "df.select(df.date,df.increment,\n",
        "     f.expr(\"\"\"add_months(date,increment) as inc_date\"\"\")\n",
        "  ).show()\n",
        "# This yields same output as above"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K39vjHqD-zLd",
        "outputId": "165cf063-8e7b-4efc-bae9-830a9f3b4f52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+----------+\n",
            "|      date|increment|  inc_date|\n",
            "+----------+---------+----------+\n",
            "|2019-01-23|        1|2019-02-23|\n",
            "|2019-06-24|        2|2019-08-24|\n",
            "|2019-09-20|        3|2019-12-20|\n",
            "+----------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Cast() Function to change data type\n",
        "df.select(\"increment\",f.expr(\"cast(increment as string) as str_increment\")) \\\n",
        "  .printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSmVwNzA-zQ3",
        "outputId": "6632c191-8453-49bf-f4bb-2bf49a7fb05b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- increment: long (nullable = true)\n",
            " |-- str_increment: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(100,2),(200,3000),(500,500)]\n",
        "df=spark.createDataFrame(data).toDF(\"col1\",\"col2\")\n",
        "df.filter(f.expr(\"col1 == col2\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICBQd7N8-zVh",
        "outputId": "8ca4d09b-e05a-430f-e5c6-d3773d9db6be"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+\n",
            "|col1|col2|\n",
            "+----+----+\n",
            "| 500| 500|\n",
            "+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"111\",50000),(\"222\",60000),(\"333\",40000)]\n",
        "columns= [\"EmpId\",\"Salary\"]\n",
        "df = spark.createDataFrame(data = data, schema = columns)\n",
        "\n",
        "df2 = df.select(\"EmpId\",\"Salary\",f.lit(\"1\").alias(\"lit_value1\"))\n",
        "df2.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q49kCwj1-zZv",
        "outputId": "e79bafe5-a636-4245-8509-ea4e8f70bf40"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+----------+\n",
            "|EmpId|Salary|lit_value1|\n",
            "+-----+------+----------+\n",
            "|111  |50000 |1         |\n",
            "|222  |60000 |1         |\n",
            "|333  |40000 |1         |\n",
            "+-----+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df2.withColumn(\"lit_value2\", f.when((f.col(\"Salary\") >=40000) & (f.col(\"Salary\") <=50000),f.lit(\"100\")).otherwise(f.lit(\"200\")))\n",
        "df3.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWUmZmW9-zeG",
        "outputId": "3ca0ce87-f25f-4dbb-f03a-14a7e69dadb8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+----------+----------+\n",
            "|EmpId|Salary|lit_value1|lit_value2|\n",
            "+-----+------+----------+----------+\n",
            "|111  |50000 |1         |100       |\n",
            "|222  |60000 |1         |200       |\n",
            "|333  |40000 |1         |100       |\n",
            "+-----+------+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"James, A, Smith\",\"2018\",\"M\",3000),\n",
        "            (\"Michael, Rose, Jones\",\"2010\",\"M\",4000),\n",
        "            (\"Robert,K,Williams\",\"2010\",\"M\",4000),\n",
        "            (\"Maria,Anne,Jones\",\"2005\",\"F\",4000),\n",
        "            (\"Jen,Mary,Brown\",\"2010\",\"\",-1)\n",
        "            ]\n",
        "\n",
        "columns=[\"name\",\"dob_year\",\"gender\",\"salary\"]\n",
        "df=spark.createDataFrame(data,columns)\n",
        "df.printSchema()\n",
        "\n",
        "df2 = df.select(f.split(f.col(\"name\"),\",\").alias(\"NameArray\")) \\\n",
        "    .drop(\"name\")\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNi4_cFoCFF9",
        "outputId": "d867e04e-e607-485d-b43e-db9e5fcad5db"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- dob_year: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "root\n",
            " |-- NameArray: array (nullable = true)\n",
            " |    |-- element: string (containsNull = false)\n",
            "\n",
            "+--------------------+\n",
            "|           NameArray|\n",
            "+--------------------+\n",
            "| [James,  A,  Smith]|\n",
            "|[Michael,  Rose, ...|\n",
            "|[Robert, K, Willi...|\n",
            "|[Maria, Anne, Jones]|\n",
            "|  [Jen, Mary, Brown]|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"PERSON\")\n",
        "spark.sql(\"select SPLIT(name,',') as NameArray from PERSON\") \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg5N8IY1-zir",
        "outputId": "d2252d40-3df9-4bbc-801e-ceb7477172f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|           NameArray|\n",
            "+--------------------+\n",
            "| [James,  A,  Smith]|\n",
            "|[Michael,  Rose, ...|\n",
            "|[Robert, K, Willi...|\n",
            "|[Maria, Anne, Jones]|\n",
            "|  [Jen, Mary, Brown]|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"name\",\"languagesAtSchool\",\"currentState\"]\n",
        "data = [(\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],\"CA\"), \\\n",
        "    (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],\"NJ\"), \\\n",
        "    (\"Robert,,Williams\",[\"CSharp\",\"VB\"],\"NV\")]\n",
        "\n",
        "df = spark.createDataFrame(data=data,schema=columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n",
        "\n",
        "#array with multiple strings into string using comma as delimeter\n",
        "df2 = df.withColumn(\"languagesAtSchool\",\n",
        "   f.concat_ws(\",\",f.col(\"languagesAtSchool\")))\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNK9bu_s-zml",
        "outputId": "9c05fd1e-b71d-4234-b67c-8994e7589070"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- languagesAtSchool: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- currentState: string (nullable = true)\n",
            "\n",
            "+----------------+------------------+------------+\n",
            "|name            |languagesAtSchool |currentState|\n",
            "+----------------+------------------+------------+\n",
            "|James,,Smith    |[Java, Scala, C++]|CA          |\n",
            "|Michael,Rose,   |[Spark, Java, C++]|NJ          |\n",
            "|Robert,,Williams|[CSharp, VB]      |NV          |\n",
            "+----------------+------------------+------------+\n",
            "\n",
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- languagesAtSchool: string (nullable = false)\n",
            " |-- currentState: string (nullable = true)\n",
            "\n",
            "+----------------+-----------------+------------+\n",
            "|name            |languagesAtSchool|currentState|\n",
            "+----------------+-----------------+------------+\n",
            "|James,,Smith    |Java,Scala,C++   |CA          |\n",
            "|Michael,Rose,   |Spark,Java,C++   |NJ          |\n",
            "|Robert,,Williams|CSharp,VB        |NV          |\n",
            "+----------------+-----------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"ARRAY_STRING\")\n",
        "spark.sql(\"select name, concat_ws(',',languagesAtSchool) as languagesAtSchool,\" + \\\n",
        "    \" currentState from ARRAY_STRING\") \\\n",
        "    .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuFRyMWwGAOP",
        "outputId": "ca55bce2-6e56-413c-ba81-47f12bc672aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----------------+------------+\n",
            "|name            |languagesAtSchool|currentState|\n",
            "+----------------+-----------------+------------+\n",
            "|James,,Smith    |Java,Scala,C++   |CA          |\n",
            "|Michael,Rose,   |Spark,Java,C++   |NJ          |\n",
            "|Robert,,Williams|CSharp,VB        |NV          |\n",
            "+----------------+-----------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(1,\"20200828\"),(2,\"20180525\")]\n",
        "columns=[\"id\",\"date\"]\n",
        "df=spark.createDataFrame(data,columns)\n",
        "df1 = df.withColumn('year', f.substring('date', 1,4))\\\n",
        "    .withColumn('month', f.substring('date', 5,2))\\\n",
        "    .withColumn('day', f.substring('date', 7,2))\n",
        "df1.printSchema()\n",
        "df1.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6dyVU6FGASw",
        "outputId": "c12cc242-af6d-4dd5-f877-eca3616719c4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- year: string (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- day: string (nullable = true)\n",
            "\n",
            "+---+--------+----+-----+---+\n",
            "|id |date    |year|month|day|\n",
            "+---+--------+----+-----+---+\n",
            "|1  |20200828|2020|08   |28 |\n",
            "|2  |20180525|2018|05   |25 |\n",
            "+---+--------+----+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('date', f.substring('date', 1,4).alias('year'), \\\n",
        "                  f.substring('date', 5,2).alias('month'), \\\n",
        "                  f.substring('date', 7,2).alias('day')).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zduiXhGTGAW3",
        "outputId": "3bc2bd36-131d-4fdc-a882-4260fa541d99"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----+---+\n",
            "|date    |year|month|day|\n",
            "+--------+----+-----+---+\n",
            "|20200828|2020|08   |28 |\n",
            "|20180525|2018|05   |25 |\n",
            "+--------+----+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3=df.withColumn('year', f.col('date').substr(1, 4))\\\n",
        "  .withColumn('month',f.col('date').substr(5, 2))\\\n",
        "  .withColumn('day', f.col('date').substr(7, 2))\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZEfvXLVGAa1",
        "outputId": "bac7479c-9c26-449b-d84c-63bcb227a95a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+----+-----+---+\n",
            "| id|    date|year|month|day|\n",
            "+---+--------+----+-----+---+\n",
            "|  1|20200828|2020|   08| 28|\n",
            "|  2|20180525|2018|   05| 25|\n",
            "+---+--------+----+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "address = [(1,\"14851 Jeffrey Rd\",\"DE\"),\n",
        "    (2,\"43421 Margarita St\",\"NY\"),\n",
        "    (3,\"13111 Siemon Ave\",\"CA\")]\n",
        "df =spark.createDataFrame(address,[\"id\",\"address\",\"state\"])\n",
        "df.show()\n",
        "df.withColumn('address', f.regexp_replace('address', 'Rd', 'Road')) \\\n",
        "  .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cycjHK8FGAex",
        "outputId": "96806a44-1ea8-4f52-db97-311925fd98e6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------+-----+\n",
            "| id|           address|state|\n",
            "+---+------------------+-----+\n",
            "|  1|  14851 Jeffrey Rd|   DE|\n",
            "|  2|43421 Margarita St|   NY|\n",
            "|  3|  13111 Siemon Ave|   CA|\n",
            "+---+------------------+-----+\n",
            "\n",
            "+---+------------------+-----+\n",
            "|id |address           |state|\n",
            "+---+------------------+-----+\n",
            "|1  |14851 Jeffrey Road|DE   |\n",
            "|2  |43421 Margarita St|NY   |\n",
            "|3  |13111 Siemon Ave  |CA   |\n",
            "+---+------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn('address',\n",
        "    f.when(df.address.endswith('Rd'),f.regexp_replace(df.address,'Rd','Road')) \\\n",
        "   .when(f.col(\"address\").endswith('St'),f.regexp_replace(df.address,'St','Street')) \\\n",
        "   .when(df.address.endswith('Ave'),f.regexp_replace(df.address,'Ave','Avenue')) \\\n",
        "   .otherwise(df.address)) \\\n",
        "   .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DekruQJGAju",
        "outputId": "52f93cf3-6318-47a3-d38a-bd9822390c76"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------------+-----+\n",
            "|id |address               |state|\n",
            "+---+----------------------+-----+\n",
            "|1  |14851 Jeffrey Road    |DE   |\n",
            "|2  |43421 Margarita Street|NY   |\n",
            "|3  |13111 Siemon Avenue   |CA   |\n",
            "+---+----------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "address = [(1,\"14851 Jeffrey Rd\",\"DE\"),\n",
        "    (2,\"43421 Margarita St\",\"NY\"),\n",
        "    (3,\"13111 Siemon Ave\",\"CA\")]\n",
        "df =spark.createDataFrame(address,[\"id\",\"address\",\"state\"])\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pm0OWleGAoK",
        "outputId": "49108e97-463a-49c1-84d4-6d4ba5a56b5d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------+-----+\n",
            "| id|           address|state|\n",
            "+---+------------------+-----+\n",
            "|  1|  14851 Jeffrey Rd|   DE|\n",
            "|  2|43421 Margarita St|   NY|\n",
            "|  3|  13111 Siemon Ave|   CA|\n",
            "+---+------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace part of string with another string\n",
        "df = spark.createDataFrame([(\"ABCDE_XYZ\", \"FGH\")], (\"col1\", \"col2\"))\n",
        "df.select(f.overlay(\"col1\", \"col2\", 7).alias(\"overlayed\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvUJFkbUGAr8",
        "outputId": "81bdd3eb-73e7-48b7-8086-01a46f715c99"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|overlayed|\n",
            "+---------+\n",
            "|ABCDE_FGH|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.createDataFrame(\n",
        "        data = [ (\"1\",\"2019-06-24 12:01:19.000\")],\n",
        "        schema=[\"id\",\"input_timestamp\"])\n",
        "df.printSchema()\n",
        "\n",
        "#Timestamp String to DateType\n",
        "df.withColumn(\"timestamp\",f.to_timestamp(\"input_timestamp\")) \\\n",
        "  .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5ZBkhKdGAvc",
        "outputId": "f6f9e553-7b42-43ee-b585-f2af191b1496"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- input_timestamp: string (nullable = true)\n",
            "\n",
            "+---+-----------------------+-------------------+\n",
            "|id |input_timestamp        |timestamp          |\n",
            "+---+-----------------------+-------------------+\n",
            "|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|\n",
            "+---+-----------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(f.to_timestamp(f.lit('06-24-2019 12:01:19.000'),'MM-dd-yyyy HH:mm:ss.SSSS')) \\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdykLGMT30Bl",
        "outputId": "0453b341-de22-4755-f373-24eee41b2abe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------+\n",
            "|to_timestamp(06-24-2019 12:01:19.000, MM-dd-yyyy HH:mm:ss.SSSS)|\n",
            "+---------------------------------------------------------------+\n",
            "|                                            2019-06-24 12:01:19|\n",
            "+---------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SQL string to TimestampType\n",
        "spark.sql(\"select to_timestamp('2019-06-24 12:01:19.000') as timestamp\")\n",
        "#SQL CAST timestamp string to TimestampType\n",
        "spark.sql(\"select timestamp('2019-06-24 12:01:19.000') as timestamp\")\n",
        "#SQL Custom string to TimestampType\n",
        "spark.sql(\"select to_timestamp('06-24-2019 12:01:19.000','MM-dd-yyyy HH:mm:ss.SSSS') as timestamp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEzSjI2LGAy-",
        "outputId": "48481789-e024-4398-966e-91c7ea08bf0b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[timestamp: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Cast to convert Timestamp String to DateType\n",
        "df.withColumn('date_type', f.col('input_timestamp').cast('date')) \\\n",
        "       .show(truncate=False)\n",
        "\n",
        "# Using Cast to convert TimestampType to DateType\n",
        "df.withColumn('date_type', f.to_timestamp('input_timestamp').cast('date')) \\\n",
        "  .show(truncate=False)\n",
        "\n",
        "df.select(f.to_date(f.lit('06-24-2019 12:01:19.000'),'MM-dd-yyyy HH:mm:ss.SSSS')) \\\n",
        "  .show()\n",
        "\n",
        "#Timestamp String to DateType\n",
        "df.withColumn(\"date_type\",f.to_date(\"input_timestamp\")) \\\n",
        "  .show(truncate=False)\n",
        "\n",
        "\n",
        "df.withColumn(\"ts\",f.to_timestamp(f.col(\"input_timestamp\"))) \\\n",
        "  .withColumn(\"datetype\",f.to_date(f.col(\"ts\"))) \\\n",
        "  .show(truncate=False)\n",
        "\n",
        "#SQL TimestampType to DateType\n",
        "spark.sql(\"select to_date(current_timestamp) as date_type\")\n",
        "#SQL CAST TimestampType to DateType\n",
        "spark.sql(\"select date(to_timestamp('2019-06-24 12:01:19.000')) as date_type\")\n",
        "#SQL CAST timestamp string to DateType\n",
        "spark.sql(\"select date('2019-06-24 12:01:19.000') as date_type\")\n",
        "#SQL Timestamp String (default format) to DateType\n",
        "spark.sql(\"select to_date('2019-06-24 12:01:19.000') as date_type\")\n",
        "#SQL Custom Timeformat to DateType\n",
        "spark.sql(\"select to_date('06-24-2019 12:01:19.000','MM-dd-yyyy HH:mm:ss.SSSS') as date_type\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8rPlYbYGA2c",
        "outputId": "3e413b77-1df7-4e48-a6ed-fe2674d96907"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------------------+----------+\n",
            "|id |input_timestamp        |date_type |\n",
            "+---+-----------------------+----------+\n",
            "|1  |2019-06-24 12:01:19.000|2019-06-24|\n",
            "+---+-----------------------+----------+\n",
            "\n",
            "+---+-----------------------+----------+\n",
            "|id |input_timestamp        |date_type |\n",
            "+---+-----------------------+----------+\n",
            "|1  |2019-06-24 12:01:19.000|2019-06-24|\n",
            "+---+-----------------------+----------+\n",
            "\n",
            "+----------------------------------------------------------+\n",
            "|to_date(06-24-2019 12:01:19.000, MM-dd-yyyy HH:mm:ss.SSSS)|\n",
            "+----------------------------------------------------------+\n",
            "|                                                2019-06-24|\n",
            "+----------------------------------------------------------+\n",
            "\n",
            "+---+-----------------------+----------+\n",
            "|id |input_timestamp        |date_type |\n",
            "+---+-----------------------+----------+\n",
            "|1  |2019-06-24 12:01:19.000|2019-06-24|\n",
            "+---+-----------------------+----------+\n",
            "\n",
            "+---+-----------------------+-------------------+----------+\n",
            "|id |input_timestamp        |ts                 |datetype  |\n",
            "+---+-----------------------+-------------------+----------+\n",
            "|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|2019-06-24|\n",
            "+---+-----------------------+-------------------+----------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[date_type: date]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.createDataFrame([[\"1\"]],[\"id\"])\n",
        "df.select(f.current_date().alias(\"current_date\"), \\\n",
        "      f.date_format(f.current_date(),\"yyyy MM dd\").alias(\"yyyy MM dd\"), \\\n",
        "      f.date_format(f.current_timestamp(),\"MM/dd/yyyy hh:mm\").alias(\"MM/dd/yyyy\"), \\\n",
        "      f.date_format(f.current_timestamp(),\"yyyy MMM dd\").alias(\"yyyy MMMM dd\"), \\\n",
        "      f.date_format(f.current_timestamp(),\"yyyy MMMM dd E\").alias(\"yyyy MMMM dd E\") \\\n",
        "   ).show()\n",
        "\n",
        "#SQL\n",
        "\n",
        "spark.sql(\"select current_date() as current_date, \"+\n",
        "      \"date_format(current_timestamp(),'yyyy MM dd') as yyyy_MM_dd, \"+\n",
        "      \"date_format(current_timestamp(),'MM/dd/yyyy hh:mm') as MM_dd_yyyy, \"+\n",
        "      \"date_format(current_timestamp(),'yyyy MMM dd') as yyyy_MMMM_dd, \"+\n",
        "      \"date_format(current_timestamp(),'yyyy MMMM dd E') as yyyy_MMMM_dd_E\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP0OiXGgGA5w",
        "outputId": "78eb2ce0-884b-44fe-81fc-cadae1cc64d9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+----------------+------------+----------------+\n",
            "|current_date|yyyy MM dd|      MM/dd/yyyy|yyyy MMMM dd|  yyyy MMMM dd E|\n",
            "+------------+----------+----------------+------------+----------------+\n",
            "|  2023-07-21|2023 07 21|07/21/2023 06:59| 2023 Jul 21|2023 July 21 Fri|\n",
            "+------------+----------+----------------+------------+----------------+\n",
            "\n",
            "+------------+----------+----------------+------------+----------------+\n",
            "|current_date|yyyy_MM_dd|      MM_dd_yyyy|yyyy_MMMM_dd|  yyyy_MMMM_dd_E|\n",
            "+------------+----------+----------------+------------+----------------+\n",
            "|  2023-07-21|2023 07 21|07/21/2023 06:59| 2023 Jul 21|2023 July 21 Fri|\n",
            "+------------+----------+----------------+------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"1\",\"2019-07-01\"),(\"2\",\"2019-06-24\"),(\"3\",\"2019-08-24\")]\n",
        "\n",
        "df=spark.createDataFrame(data=data,schema=[\"id\",\"date\"])\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "df.select(\n",
        "      f.col(\"date\"),\n",
        "      f.current_date().alias(\"current_date\"),\n",
        "      f.datediff(current_date(),col(\"date\")).alias(\"datediff\")\n",
        "    ).show()\n",
        "\n",
        "df.withColumn(\"datesDiff\", f.datediff(current_date(),col(\"date\"))) \\\n",
        "      .withColumn(\"montsDiff\", f.months_between(current_date(),col(\"date\"))) \\\n",
        "      .withColumn(\"montsDiff_round\",round(f.months_between(current_date(),col(\"date\")),2)) \\\n",
        "      .withColumn(\"yearsDiff\",f.months_between(current_date(),col(\"date\"))/lit(12)) \\\n",
        "      .withColumn(\"yearsDiff_round\",round(f.months_between(current_date(),col(\"date\"))/lit(12),2)) \\\n",
        "      .show()\n",
        "\n",
        "data2 = [(\"1\",\"07-01-2019\"),(\"2\",\"06-24-2019\"),(\"3\",\"08-24-2019\")]\n",
        "df2=spark.createDataFrame(data=data2,schema=[\"id\",\"date\"])\n",
        "df2.select(\n",
        "    f.to_date(col(\"date\"),\"MM-dd-yyyy\").alias(\"date\"),\n",
        "    f.current_date().alias(\"endDate\")\n",
        "    )\n",
        "\n",
        "spark.sql(\"select round(months_between('2019-07-01',current_date())/12,2) as years_diff\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEAcskRBGA8k",
        "outputId": "81edaf0c-d6f7-49d4-ac5a-ac848cc6510c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+--------+\n",
            "|      date|current_date|datediff|\n",
            "+----------+------------+--------+\n",
            "|2019-07-01|  2023-07-21|    1481|\n",
            "|2019-06-24|  2023-07-21|    1488|\n",
            "|2019-08-24|  2023-07-21|    1427|\n",
            "+----------+------------+--------+\n",
            "\n",
            "+---+----------+---------+-----------+---------------+------------------+---------------+\n",
            "| id|      date|datesDiff|  montsDiff|montsDiff_round|         yearsDiff|yearsDiff_round|\n",
            "+---+----------+---------+-----------+---------------+------------------+---------------+\n",
            "|  1|2019-07-01|     1481|48.64516129|          48.65| 4.053763440833333|           4.05|\n",
            "|  2|2019-06-24|     1488|48.90322581|           48.9|4.0752688175000005|           4.08|\n",
            "|  3|2019-08-24|     1427|46.90322581|           46.9|3.9086021508333335|           3.91|\n",
            "+---+----------+---------+-----------+---------------+------------------+---------------+\n",
            "\n",
            "+----------+\n",
            "|years_diff|\n",
            "+----------+\n",
            "|     -4.05|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arrayArrayData = [\n",
        "  (\"James\",[[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"]]),\n",
        "  (\"Michael\",[[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"]]),\n",
        "  (\"Robert\",[[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"]])\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data=arrayArrayData, schema = ['name','subjects'])\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itd-a6e--zqO",
        "outputId": "92b1947c-6d4c-48c6-960b-6b274f4dcda8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- subjects: array (nullable = true)\n",
            " |    |-- element: array (containsNull = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-------+-----------------------------------+\n",
            "|name   |subjects                           |\n",
            "+-------+-----------------------------------+\n",
            "|James  |[[Java, Scala, C++], [Spark, Java]]|\n",
            "|Michael|[[Spark, Java, C++], [Spark, Java]]|\n",
            "|Robert |[[CSharp, VB], [Spark, Python]]    |\n",
            "+-------+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.name,f.explode(df.subjects)).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ibc9DAhShqE",
        "outputId": "557fced1-9760-41b6-d020-62c596a73e1f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|name   |col               |\n",
            "+-------+------------------+\n",
            "|James  |[Java, Scala, C++]|\n",
            "|James  |[Spark, Java]     |\n",
            "|Michael|[Spark, Java, C++]|\n",
            "|Michael|[Spark, Java]     |\n",
            "|Robert |[CSharp, VB]      |\n",
            "|Robert |[Spark, Python]   |\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arrayCol = f.ArrayType(f.StringType(),False)\n",
        "data = [\n",
        " (\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"],\"OH\",\"CA\"),\n",
        " (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"],\"NY\",\"NJ\"),\n",
        " (\"Robert,,Williams\",[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"],\"UT\",\"NV\")\n",
        "]\n",
        "from pyspark.sql.types import StringType, ArrayType,StructType,StructField\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"name\",StringType(),True),\n",
        "    StructField(\"languagesAtSchool\",ArrayType(StringType()),True),\n",
        "    StructField(\"languagesAtWork\",ArrayType(StringType()),True),\n",
        "    StructField(\"currentState\", StringType(), True),\n",
        "    StructField(\"previousState\", StringType(), True)\n",
        "  ])\n",
        "\n",
        "df = spark.createDataFrame(data=data,schema=schema)\n",
        "df.printSchema()\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqGKCFBxShzI",
        "outputId": "b9bead9e-7b5f-478f-f913-e4db07a8f916"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- languagesAtSchool: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- languagesAtWork: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- currentState: string (nullable = true)\n",
            " |-- previousState: string (nullable = true)\n",
            "\n",
            "+----------------+------------------+---------------+------------+-------------+\n",
            "|            name| languagesAtSchool|languagesAtWork|currentState|previousState|\n",
            "+----------------+------------------+---------------+------------+-------------+\n",
            "|    James,,Smith|[Java, Scala, C++]|  [Spark, Java]|          OH|           CA|\n",
            "|   Michael,Rose,|[Spark, Java, C++]|  [Spark, Java]|          NY|           NJ|\n",
            "|Robert,,Williams|      [CSharp, VB]|[Spark, Python]|          UT|           NV|\n",
            "+----------------+------------------+---------------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(f.split(df.name,\",\").alias(\"nameAsArray\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFkjpar4Sh5I",
        "outputId": "9ad8fe83-fc4b-4978-8d91-f5e8293f7378"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|         nameAsArray|\n",
            "+--------------------+\n",
            "|    [James, , Smith]|\n",
            "|   [Michael, Rose, ]|\n",
            "|[Robert, , Williams]|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.name,f.array(df.currentState,df.previousState).alias(\"States\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lc__7oESh9z",
        "outputId": "e53992b2-0341-4b41-bf37-0e0a222ac47e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------+\n",
            "|            name|  States|\n",
            "+----------------+--------+\n",
            "|    James,,Smith|[OH, CA]|\n",
            "|   Michael,Rose,|[NY, NJ]|\n",
            "|Robert,,Williams|[UT, NV]|\n",
            "+----------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.name,f.array_contains(df.languagesAtSchool,\"Java\")\n",
        "    .alias(\"array_contains\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnf24BKxSiB-",
        "outputId": "c00bd99e-be1a-47b1-afdc-d72bca653d63"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------+\n",
            "|            name|array_contains|\n",
            "+----------------+--------------+\n",
            "|    James,,Smith|          true|\n",
            "|   Michael,Rose,|          true|\n",
            "|Robert,,Williams|         false|\n",
            "+----------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simpleData = [(\"James\", \"Sales\", 3000),\n",
        "    (\"Michael\", \"Sales\", 4600),\n",
        "    (\"Robert\", \"Sales\", 4100),\n",
        "    (\"Maria\", \"Finance\", 3000),\n",
        "    (\"James\", \"Sales\", 3000),\n",
        "    (\"Scott\", \"Finance\", 3300),\n",
        "    (\"Jen\", \"Finance\", 3900),\n",
        "    (\"Jeff\", \"Marketing\", 3000),\n",
        "    (\"Kumar\", \"Marketing\", 2000),\n",
        "    (\"Saif\", \"Sales\", 4100)\n",
        "  ]\n",
        "schema = [\"employee_name\", \"department\", \"salary\"]\n",
        "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3L9RoZdSiHE",
        "outputId": "d6405799-1f0b-4364-f59e-e9208a0f5d2e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|James        |Sales     |3000  |\n",
            "|Michael      |Sales     |4600  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Maria        |Finance   |3000  |\n",
            "|James        |Sales     |3000  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Saif         |Sales     |4100  |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#//approx_count_distinct()\n",
        "print(\"approx_count_distinct: \" + \\\n",
        "      str(df.select(approx_count_distinct(\"salary\")).collect()[0][0]))\n",
        "\n",
        "#//Prints approx_count_distinct: 6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyn3Xi11SiLr",
        "outputId": "602fe197-710f-4ecb-b6e7-e26cfe868504"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "approx_count_distinct: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"avg: \" + str(df.select(avg(\"salary\")).collect()[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxZoCm-sWgl5",
        "outputId": "c921a08d-c9ef-4ba8-f88a-8949f1eedf34"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg: 3400.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#//collect_list\n",
        "df.select(collect_list(\"salary\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLSVcxFEWgqi",
        "outputId": "bc1df7e7-616a-47b9-d563-c8869c258ff0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------+\n",
            "|collect_list(salary)                                        |\n",
            "+------------------------------------------------------------+\n",
            "|[3000, 4600, 4100, 3000, 3000, 3300, 3900, 3000, 2000, 4100]|\n",
            "+------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#//countDistinct\n",
        "df2 = df.select(f.countDistinct(\"department\", \"salary\"))\n",
        "df2.show(truncate=False)\n",
        "print(\"Distinct Count of Department & Salary: \"+str(df2.collect()[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d_oYr-lWguj",
        "outputId": "c3e4ee84-b8ef-47ff-ac90-f4247120f95b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------+\n",
            "|count(DISTINCT department, salary)|\n",
            "+----------------------------------+\n",
            "|8                                 |\n",
            "+----------------------------------+\n",
            "\n",
            "Distinct Count of Department & Salary: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"count: \"+str(df.select(count(\"salary\")).collect()[0]))\n",
        "df.select(first(\"salary\")).show(truncate=False)\n",
        "df.select(last(\"salary\")).show(truncate=False)\n",
        "df.select(kurtosis(\"salary\")).show(truncate=False)\n",
        "df.select(max(\"salary\")).show(truncate=False)\n",
        "df.select(min(\"salary\")).show(truncate=False)\n",
        "df.select(mean(\"salary\")).show(truncate=False)\n",
        "df.select(skewness(\"salary\")).show(truncate=False)\n",
        "df.select(stddev(\"salary\"), stddev_samp(\"salary\"), \\\n",
        "    stddev_pop(\"salary\")).show(truncate=False)\n",
        "df.select(sum(\"salary\")).show(truncate=False)\n",
        "df.select(sumDistinct(\"salary\")).show(truncate=False)\n",
        "df.select(variance(\"salary\"),var_samp(\"salary\"),var_pop(\"salary\")) \\\n",
        "  .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuGlNecdWgyj",
        "outputId": "c4f225df-8806-4a6f-f525-da5ec6bd377c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: Row(count(salary)=10)\n",
            "+-------------+\n",
            "|first(salary)|\n",
            "+-------------+\n",
            "|3000         |\n",
            "+-------------+\n",
            "\n",
            "+------------+\n",
            "|last(salary)|\n",
            "+------------+\n",
            "|4100        |\n",
            "+------------+\n",
            "\n",
            "+-------------------+\n",
            "|kurtosis(salary)   |\n",
            "+-------------------+\n",
            "|-0.6467803030303032|\n",
            "+-------------------+\n",
            "\n",
            "+-----------+\n",
            "|max(salary)|\n",
            "+-----------+\n",
            "|4600       |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|min(salary)|\n",
            "+-----------+\n",
            "|2000       |\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|avg(salary)|\n",
            "+-----------+\n",
            "|3400.0     |\n",
            "+-----------+\n",
            "\n",
            "+--------------------+\n",
            "|skewness(salary)    |\n",
            "+--------------------+\n",
            "|-0.12041791181069571|\n",
            "+--------------------+\n",
            "\n",
            "+-------------------+-------------------+------------------+\n",
            "|stddev_samp(salary)|stddev_samp(salary)|stddev_pop(salary)|\n",
            "+-------------------+-------------------+------------------+\n",
            "|765.9416862050705  |765.9416862050705  |726.636084983398  |\n",
            "+-------------------+-------------------+------------------+\n",
            "\n",
            "+-----------+\n",
            "|sum(salary)|\n",
            "+-----------+\n",
            "|34000      |\n",
            "+-----------+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/functions.py:752: FutureWarning: Deprecated in 3.2, use sum_distinct instead.\n",
            "  warnings.warn(\"Deprecated in 3.2, use sum_distinct instead.\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|sum(DISTINCT salary)|\n",
            "+--------------------+\n",
            "|20900               |\n",
            "+--------------------+\n",
            "\n",
            "+-----------------+-----------------+---------------+\n",
            "|var_samp(salary) |var_samp(salary) |var_pop(salary)|\n",
            "+-----------------+-----------------+---------------+\n",
            "|586666.6666666666|586666.6666666666|528000.0       |\n",
            "+-----------------+-----------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nyR1JAdoWg2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OoKEHckkWg6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZeaWwEYKWg_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YUjrhTqfWhFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "udr8wUYXSiPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dU9P-2A2SiTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xyYLS0wKcwO_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}